{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "433747c7-bf28-4504-99a5-ac1cf0281e95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1407818079788496#setting/sparkui/0611-043343-dvbo736r/driver-790494521946126491\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7aa5b4d7cd50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Set-2\").getOrCreate()\n",
    "spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96f4d3e1-c080-43ec-8df6-30321f3c2310",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+--------+-------+-------+\n|UserID|Page    |Timestamp          |Duration|Device |Country|\n+------+--------+-------------------+--------+-------+-------+\n|1     |Home    |2024-04-10 10:00:00|35      |Mobile |India  |\n|2     |Products|2024-04-10 10:02:00|120     |Desktop|USA    |\n|3     |Cart    |2024-04-10 10:05:00|45      |Tablet |UK     |\n|1     |Checkout|2024-04-10 10:08:00|60      |Mobile |India  |\n|4     |Home    |2024-04-10 10:10:00|15      |Mobile |Canada |\n|2     |Contact |2024-04-10 10:15:00|25      |Desktop|USA    |\n|5     |Products|2024-04-10 10:20:00|90      |Desktop|India  |\n+------+--------+-------------------+--------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql import Row\n",
    "\n",
    "web_data = [\n",
    "    Row(UserID=1, Page=\"Home\", Timestamp=\"2024-04-10 10:00:00\", Duration=35,\n",
    "Device=\"Mobile\", Country=\"India\"),\n",
    "    Row(UserID=2, Page=\"Products\", Timestamp=\"2024-04-10 10:02:00\", Duration=120,\n",
    "Device=\"Desktop\", Country=\"USA\"),\n",
    "    Row(UserID=3, Page=\"Cart\", Timestamp=\"2024-04-10 10:05:00\", Duration=45,\n",
    "Device=\"Tablet\", Country=\"UK\"),\n",
    "    Row(UserID=1, Page=\"Checkout\", Timestamp=\"2024-04-10 10:08:00\", Duration=60,\n",
    "Device=\"Mobile\", Country=\"India\"),\n",
    "    Row(UserID=4, Page=\"Home\", Timestamp=\"2024-04-10 10:10:00\", Duration=15,\n",
    "Device=\"Mobile\", Country=\"Canada\"),\n",
    "    Row(UserID=2, Page=\"Contact\", Timestamp=\"2024-04-10 10:15:00\", Duration=25,\n",
    "Device=\"Desktop\", Country=\"USA\"),\n",
    "    Row(UserID=5, Page=\"Products\", Timestamp=\"2024-04-10 10:20:00\", Duration=90,\n",
    "Device=\"Desktop\", Country=\"India\"),\n",
    "]\n",
    "df_web = spark.createDataFrame(web_data)\n",
    "df_web.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "130d64c4-8045-4f44-b430-455f345819ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Data Exploration & Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60b2a1f0-4df6-4b8f-adcb-09c9999ea365",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- UserID: long (nullable = true)\n |-- Page: string (nullable = true)\n |-- Timestamp: string (nullable = true)\n |-- Duration: long (nullable = true)\n |-- Device: string (nullable = true)\n |-- Country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# 1. Display the schema of web_traffic_data .\n",
    "\n",
    "df_web.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a00d5765-d051-4b6c-b1db-aba9d0fa379e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+--------+-------+-------+\n|UserID|    Page|          Timestamp|Duration| Device|Country|\n+------+--------+-------------------+--------+-------+-------+\n|     1|    Home|2024-04-10 10:00:00|      35| Mobile|  India|\n|     2|Products|2024-04-10 10:02:00|     120|Desktop|    USA|\n|     3|    Cart|2024-04-10 10:05:00|      45| Tablet|     UK|\n|     1|Checkout|2024-04-10 10:08:00|      60| Mobile|  India|\n|     4|    Home|2024-04-10 10:10:00|      15| Mobile| Canada|\n|     2| Contact|2024-04-10 10:15:00|      25|Desktop|    USA|\n|     5|Products|2024-04-10 10:20:00|      90|Desktop|  India|\n+------+--------+-------------------+--------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# 2. Convert the Timestamp column to a proper timestamp type.\n",
    "\n",
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "df_web = df_web.withColumn(\"Timestamp\",to_timestamp(\"Timestamp\",\"yyyy-MM-dd HH:mm:ss\"))\n",
    "df_web.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a47583fb-9a69-450a-ab88-2cc50cb28437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+--------+-------+-------+-------------+\n|UserID|    Page|          Timestamp|Duration| Device|Country|SessionMinute|\n+------+--------+-------------------+--------+-------+-------+-------------+\n|     1|    Home|2024-04-10 10:00:00|      35| Mobile|  India|            0|\n|     2|Products|2024-04-10 10:02:00|     120|Desktop|    USA|            2|\n|     3|    Cart|2024-04-10 10:05:00|      45| Tablet|     UK|            5|\n|     1|Checkout|2024-04-10 10:08:00|      60| Mobile|  India|            8|\n|     4|    Home|2024-04-10 10:10:00|      15| Mobile| Canada|           10|\n|     2| Contact|2024-04-10 10:15:00|      25|Desktop|    USA|           15|\n|     5|Products|2024-04-10 10:20:00|      90|Desktop|  India|           20|\n+------+--------+-------------------+--------+-------+-------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 3. Add a new column SessionMinute by extracting the minute from the Timestamp .\n",
    "from pyspark.sql.functions import minute\n",
    "\n",
    "df_web = df_web.withColumn(\"SessionMinute\",minute(\"Timestamp\"))\n",
    "df_web.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "602e9809-fc1b-4a3b-97de-b2e39092920e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Filtering and Conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a93606e-e554-4956-baa9-00fcf90a55de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+--------+------+-------+-------------+\n|UserID|    Page|          Timestamp|Duration|Device|Country|SessionMinute|\n+------+--------+-------------------+--------+------+-------+-------------+\n|     1|Checkout|2024-04-10 10:08:00|      60|Mobile|  India|            8|\n+------+--------+-------------------+--------+------+-------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 4. Filter users who used a \"Mobile\" device and visited the \"Checkout\" page.\n",
    "\n",
    "df_web.filter((df_web.Device == \"Mobile\") & (df_web.Page == \"Checkout\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55bdadcf-95c8-4f32-8a05-572b39879173",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+--------+-------+-------+-------------+\n|UserID|    Page|          Timestamp|Duration| Device|Country|SessionMinute|\n+------+--------+-------------------+--------+-------+-------+-------------+\n|     2|Products|2024-04-10 10:02:00|     120|Desktop|    USA|            2|\n|     5|Products|2024-04-10 10:20:00|      90|Desktop|  India|           20|\n+------+--------+-------------------+--------+-------+-------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 5. Show all entries with a Duration greater than 60 seconds.\n",
    "\n",
    "df_web.filter(df_web.Duration > 60).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d9e05fe-fcf3-4214-8d05-639d90edad5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+--------+-------+-------+-------------+\n|UserID|    Page|          Timestamp|Duration| Device|Country|SessionMinute|\n+------+--------+-------------------+--------+-------+-------+-------------+\n|     5|Products|2024-04-10 10:20:00|      90|Desktop|  India|           20|\n+------+--------+-------------------+--------+-------+-------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 6. Find all users from India who visited the \"Products\" page.\n",
    "\n",
    "df_web.filter((df_web.Country == \"India\") & (df_web.Page == \"Products\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59829495-da7e-4f44-8723-ea32b3556d68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Aggregation and Grouping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "100bd1b9-f7ab-4899-860c-03524704a697",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n| Device|     avg(Duration)|\n+-------+------------------+\n| Mobile|36.666666666666664|\n| Tablet|              45.0|\n|Desktop| 78.33333333333333|\n+-------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 7. Get the average duration per device type.\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df_web.groupBy(\"Device\").agg(avg(\"Duration\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c43bab55-1920-4340-aede-79ba8d43538a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n|Country|count(UserId)|\n+-------+-------------+\n|  India|            3|\n|    USA|            2|\n|     UK|            1|\n| Canada|            1|\n+-------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 8. Count the number of sessions per country.\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "df_web.groupBy(\"Country\").agg(count(\"UserId\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "309f5a63-38c1-4029-8c93-4d3e4f0e3ef4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n|    Page|max(Duration)|\n+--------+-------------+\n|    Home|           35|\n|    Cart|           45|\n|Products|          120|\n|Checkout|           60|\n| Contact|           25|\n+--------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 9. Find the most visited page overall.\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "df_web.groupBy(\"Page\").agg(max(\"Duration\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5959a97-05e5-4a00-a444-ab7908cd3bd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Window Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4315f002-36a9-4ca7-ab06-ce6ee4466826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+--------+-------+-------+-------------+----+------+\n|UserID|    Page|          Timestamp|Duration| Device|Country|SessionMinute|rank|Ranked|\n+------+--------+-------------------+--------+-------+-------+-------------+----+------+\n|     1|    Home|2024-04-10 10:00:00|      35| Mobile|  India|            0|   1|     1|\n|     1|Checkout|2024-04-10 10:08:00|      60| Mobile|  India|            8|   2|     2|\n|     2|Products|2024-04-10 10:02:00|     120|Desktop|    USA|            2|   1|     1|\n|     2| Contact|2024-04-10 10:15:00|      25|Desktop|    USA|           15|   2|     2|\n|     3|    Cart|2024-04-10 10:05:00|      45| Tablet|     UK|            5|   1|     1|\n|     4|    Home|2024-04-10 10:10:00|      15| Mobile| Canada|           10|   1|     1|\n|     5|Products|2024-04-10 10:20:00|      90|Desktop|  India|           20|   1|     1|\n+------+--------+-------------------+--------+-------+-------+-------------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# 10. Rank each userâ€™s pages by timestamp (oldest to newest).\n",
    "\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "user_window = Window.partitionBy(\"UserID\").orderBy(\"Timestamp\")\n",
    "df_web = df_web.withColumn(\"rank\",row_number().over(user_window))\n",
    "df_ranked = df_web.withColumn(\"Ranked\",row_number().over(user_window))\n",
    "df_ranked.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8270e8e0-503d-4498-83ba-6d3facf8cda1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n|UserID|sum(Duration)|\n+------+-------------+\n|     1|           95|\n|     3|           45|\n|     2|          145|\n|     4|           15|\n|     5|           90|\n+------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 11. Find the total duration of all sessions per user using groupBy .\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df_ranked.groupBy(\"UserID\").agg(sum(\"Duration\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3e18bc9-2cb8-48f9-a745-1bb314414400",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Spark SQL Tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "280e1b87-6065-4014-8f57-d83ed262fd98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 12. Create a temporary view called traffic_view .\n",
    "\n",
    "df_ranked.createOrReplaceTempView(\"traffic_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f00de42b-4a85-4930-93f4-b3ba40f48ac2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+--------+-------+-------+-------------+----+------+\n|UserID|    Page|          Timestamp|Duration| Device|Country|SessionMinute|rank|Ranked|\n+------+--------+-------------------+--------+-------+-------+-------------+----+------+\n|     2|Products|2024-04-10 10:02:00|     120|Desktop|    USA|            2|   1|     1|\n|     5|Products|2024-04-10 10:20:00|      90|Desktop|  India|           20|   1|     1|\n+------+--------+-------------------+--------+-------+-------+-------------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# 13. Write a SQL query to get the top 2 longest sessions by duration.\n",
    "\n",
    "spark.sql(\"select * from traffic_view order by Duration desc limit 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd6ee9e8-717e-4442-b71e-cded41c2acb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n|    page|uniqueuser|\n+--------+----------+\n|    Cart|         1|\n|    Home|         2|\n|Checkout|         1|\n|Products|         2|\n| Contact|         1|\n+--------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 14. Get the number of unique users per page using SQL.\n",
    "\n",
    "spark.sql(\"select page,count(distinct UserID) as uniqueuser from traffic_view group by page\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c875e6a6-9682-4a16-b943-00a01d00ad29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Export & Save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c2ce7b3-7ada-4a01-882e-95016d8a4ae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 15. Save the final DataFrame to CSV.\n",
    "df_web.write.mode(\"overwrite\").option(\"header\", True).csv(\"/dbfs/FileStore/shared/converted_csv_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8683bdef-746e-441b-be37-3a3740e6f8d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 16. Save partitioned by Country in Parquet format.\n",
    "df_web.write .mode(\"overwrite\").partitionBy(\"Country\").parquet(\"/dbfs/FileStore/shared/partitioned_parquet_output\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "June 12 - Set 2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}