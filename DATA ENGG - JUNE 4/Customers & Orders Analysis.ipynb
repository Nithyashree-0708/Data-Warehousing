{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afbd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, when, col, concat_ws, regexp_replace, to_date, datediff, udf\n",
    "from pyspark.sql.types import StringType\n",
    "spark = SparkSession.builder.appName(\"PracticeProject_FriendVersion\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# Customers data with slightly changed names and cities\n",
    "customers_data = [\n",
    "    (101, 'Manikandan', 'manikandan@gmail.com', 'Chennai', '2022-05-10'),\n",
    "    (102, 'Saravanan', 'saravanan@yahoo.com', 'Delhi', '2023-01-15'),\n",
    "    (103, 'Motesh', 'motesh@hotmail.com', 'Bengaluru', '2021-11-01'),\n",
    "    (104, 'Manoj', 'manoj@outlook.com', 'Hyderabad', '2020-07-22'),\n",
    "    (105, 'Jeevan', 'jeevan@gmail.com', 'Coimbatore', '2023-03-10'),\n",
    "]\n",
    "\n",
    "orders_data = [\n",
    "    (1, 101, 'Laptop', 'Electronics', 2, 50000.0, '2024-01-10'),\n",
    "    (2, 101, 'Mouse', 'Electronics', 1, 1200.0, '2024-01-15'),\n",
    "    (3, 102, 'Tablet', 'Electronics', 1, 20000.0, '2024-02-01'),\n",
    "    (4, 103, 'Bookshelf', 'Furniture', 1, 3500.0, '2024-02-10'),\n",
    "    (5, 104, 'Mixer', 'Appliances', 1, 5000.0, '2024-02-15'),\n",
    "    (6, 105, 'Notebook', 'Stationery', 5, 500.0, '2024-03-01'),\n",
    "    (7, 102, 'Phone', 'Electronics', 1, 30000.0, '2024-03-02'),\n",
    "]\n",
    "\n",
    "cust_df = spark.createDataFrame(customers_data, [\"CustomerID\", \"Name\", \"Email\", \"City\", \"SignupDate\"])\n",
    "ord_df = spark.createDataFrame(orders_data, [\"OrderID\", \"CustomerID\", \"Product\", \"Category\", \"Quantity\", \"Price\", \"OrderDate\"])\n",
    "\n",
    "# Save as tables\n",
    "cust_df.write.mode(\"overwrite\").saveAsTable(\"practice.customers\")\n",
    "ord_df.write.mode(\"overwrite\").saveAsTable(\"practice.orders\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e510011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Add TotalAmount column\n",
    "ord_df = ord_df.withColumn(\"TotalAmount\", col(\"Price\") * col(\"Quantity\"))\n",
    "ord_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Filter orders with TotalAmount > 10000\n",
    "ord_df.filter(col(\"TotalAmount\") > 10000).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Lowercase City in customers\n",
    "cust_df = cust_df.withColumn(\"City\", expr(\"lower(City)\"))\n",
    "cust_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Extract OrderYear from OrderDate\n",
    "ord_df = ord_df.withColumn(\"OrderYear\", expr(\"year(to_date(OrderDate))\"))\n",
    "ord_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b525fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Fill null Email with default\n",
    "cust_df = cust_df.na.fill({\"Email\": \"unknown@example.com\"})\n",
    "cust_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Categorize orders by TotalAmount\n",
    "ord_df = ord_df.withColumn(\"CategoryLevel\", when(col(\"TotalAmount\") < 5000, \"Low\")                           .when((col(\"TotalAmount\") >= 5000) & (col(\"TotalAmount\") <= 20000), \"Medium\")                           .otherwise(\"High\"))\n",
    "ord_df.select(\"OrderID\", \"TotalAmount\", \"CategoryLevel\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539fa158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. SQL Query: Orders by Manikandan\n",
    "spark.sql(\"\"\"\n",
    "SELECT o.* FROM practice.customers c\n",
    "JOIN practice.orders o ON c.CustomerID = o.CustomerID\n",
    "WHERE c.Name = 'Manikandan'\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. SQL: Total spending per customer\n",
    "spark.sql(\"\"\"\n",
    "SELECT c.Name, SUM(o.TotalAmount) AS TotalSpent\n",
    "FROM practice.customers c\n",
    "JOIN practice.orders o ON c.CustomerID = o.CustomerID\n",
    "GROUP BY c.Name\n",
    "ORDER BY TotalSpent DESC\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18477b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. SQL: Category with highest total revenue\n",
    "spark.sql(\"\"\"\n",
    "SELECT Category, SUM(TotalAmount) AS TotalRevenue\n",
    "FROM practice.orders\n",
    "GROUP BY Category\n",
    "ORDER BY TotalRevenue DESC\n",
    "LIMIT 1\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eedf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Create view customer_orders\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE VIEW practice.customer_orders AS\n",
    "SELECT c.Name AS CustomerName, o.Product, o.TotalAmount\n",
    "FROM practice.customers c\n",
    "JOIN practice.orders o ON c.CustomerID = o.CustomerID\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Query customer_orders for products ordered after Feb 2024\n",
    "spark.sql(\"\"\"\n",
    "SELECT * FROM practice.customer_orders co\n",
    "JOIN practice.orders o ON co.Product = o.Product\n",
    "WHERE o.OrderDate > '2024-02-28'\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eef703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Global temp view and query\n",
    "cust_df.createGlobalTempView(\"customers\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT * FROM global_temp.customers WHERE City = 'chennai'\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Save orders with TotalAmount to Parquet\n",
    "ord_df.write.mode(\"overwrite\").parquet(\"/tmp/practice_orders.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Read Parquet and count\n",
    "parquet_df = spark.read.parquet(\"/tmp/practice_orders.parquet\")\n",
    "print(f\"Orders count in parquet: {parquet_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. UDF to mask email\n",
    "def mask_email(email):\n",
    "    if email and '@' in email:\n",
    "        parts = email.split('@')\n",
    "        return parts[0][0] + '***@' + parts[1]\n",
    "    return email\n",
    "\n",
    "mask_email_udf = udf(mask_email, StringType())\n",
    "cust_df = cust_df.withColumn(\"MaskedEmail\", mask_email_udf(col(\"Email\")))\n",
    "cust_df.select(\"Email\", \"MaskedEmail\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Create full label\n",
    "cust_df = cust_df.withColumn(\"FullLabel\", concat_ws(\" \", col(\"Name\"), lit(\"from\"), col(\"City\")))\n",
    "cust_df.select(\"FullLabel\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae1d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Clean Product names\n",
    "ord_df = ord_df.withColumn(\"CleanProduct\", regexp_replace(col(\"Product\"), \"[^a-zA-Z0-9 ]\", \"\"))\n",
    "ord_df.select(\"Product\", \"CleanProduct\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Customer age in days\n",
    "from pyspark.sql.functions import current_date\n",
    "cust_df = cust_df.withColumn(\"SignupDate_dt\", to_date(col(\"SignupDate\")))\n",
    "cust_df = cust_df.withColumn(\"AgeInDays\", datediff(current_date(), col(\"SignupDate_dt\")))\n",
    "cust_df.select(\"Name\", \"SignupDate\", \"AgeInDays\").show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
