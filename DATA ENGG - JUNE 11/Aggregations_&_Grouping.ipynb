{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IXuOwIGqOPoc"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, avg, count, max, min, when, rank, sum as _sum, current_date, datediff\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import lit, expr\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AdvancedEmployeeData\").getOrCreate()\n",
        "\n",
        "# Employee dataset\n",
        "data = [\n",
        "    (\"Ananya\", \"HR\", 52000),\n",
        "    (\"Rahul\", \"Engineering\", 65000),\n",
        "    (\"Priya\", \"Engineering\", 60000),\n",
        "    (\"Zoya\", \"Marketing\", 48000),\n",
        "    (\"Karan\", \"HR\", 53000),\n",
        "    (\"Naveen\", \"Engineering\", 70000),\n",
        "    (\"Fatima\", \"Marketing\", 45000)\n",
        "]\n",
        "columns = [\"Name\", \"Department\", \"Salary\"]\n",
        "df_emp = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Performance dataset\n",
        "performance = [\n",
        "    (\"Ananya\", 2023, 4.5),\n",
        "    (\"Rahul\", 2023, 4.9),\n",
        "    (\"Priya\", 2023, 4.3),\n",
        "    (\"Zoya\", 2023, 3.8),\n",
        "    (\"Karan\", 2023, 4.1),\n",
        "    (\"Naveen\", 2023, 4.7),\n",
        "    (\"Fatima\", 2023, 3.9)\n",
        "]\n",
        "columns_perf = [\"Name\", \"Year\", \"Rating\"]\n",
        "df_perf = spark.createDataFrame(performance, columns_perf)\n",
        "# Define the random date generator function\n",
        "def random_date():\n",
        "    start_date = datetime(2020, 1, 1)\n",
        "    end_date = datetime(2023, 12, 31)\n",
        "    delta = end_date - start_date\n",
        "    rand_days = random.randint(0, delta.days)\n",
        "    return (start_date + timedelta(days=rand_days)).strftime(\"%Y-%m-%d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GroupBy and Aggregations**\n"
      ],
      "metadata": {
        "id": "MBFhsw1VOmFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Average salary by department\n",
        "df_emp.groupBy(\"Department\").agg(avg(\"Salary\").alias(\"AverageSalary\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDMhJgu3OoR2",
        "outputId": "25f3245c-c467-46f9-ab2d-fa15b845da63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+\n",
            "| Department|AverageSalary|\n",
            "+-----------+-------------+\n",
            "|Engineering|      65000.0|\n",
            "|         HR|      52500.0|\n",
            "|  Marketing|      46500.0|\n",
            "+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Count of employees per department\n",
        "df_emp.groupBy(\"Department\").agg(count(\"Name\").alias(\"EmployeeCount\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gZ-JC_uPIAQ",
        "outputId": "55d32587-624b-444b-d903-6cc9964318c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+\n",
            "| Department|EmployeeCount|\n",
            "+-----------+-------------+\n",
            "|Engineering|            3|\n",
            "|         HR|            2|\n",
            "|  Marketing|            2|\n",
            "+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Maximum and minimum salary in Engineering\n",
        "df_emp.filter(col(\"Department\") == \"Engineering\").agg(\n",
        "    max(\"Salary\").alias(\"MaxSalary\"),\n",
        "    min(\"Salary\").alias(\"MinSalary\")\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi0TEbRJPRLR",
        "outputId": "b1c4ed7d-8f8c-4898-af32-bd8882c2ee37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+\n",
            "|MaxSalary|MinSalary|\n",
            "+---------+---------+\n",
            "|    70000|    60000|\n",
            "+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Join and Combine Data**"
      ],
      "metadata": {
        "id": "oHW-T1yXPq7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Inner join on Name\n",
        "df_joined = df_emp.join(df_perf, on=\"Name\", how=\"inner\")"
      ],
      "metadata": {
        "id": "OB_zbDjlPdMs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Each employeeâ€™s salary and performance rating\n",
        "df_joined.select(\"Name\", \"Salary\", \"Rating\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1B0HdRKPyRp",
        "outputId": "7d77f6dc-a75c-45d6-f846-853107b07aa9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+------+\n",
            "|  Name|Salary|Rating|\n",
            "+------+------+------+\n",
            "|Ananya| 52000|   4.5|\n",
            "|Fatima| 45000|   3.9|\n",
            "| Karan| 53000|   4.1|\n",
            "|Naveen| 70000|   4.7|\n",
            "| Priya| 60000|   4.3|\n",
            "| Rahul| 65000|   4.9|\n",
            "|  Zoya| 48000|   3.8|\n",
            "+------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Filter: rating > 4.5 and salary > 60000\n",
        "df_joined.filter((col(\"Rating\") > 4.5) & (col(\"Salary\") > 60000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-LeruMWQU4q",
        "outputId": "b69a5126-4c5b-41fb-8bba-347fce34e27e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----+------+\n",
            "|  Name| Department|Salary|Year|Rating|\n",
            "+------+-----------+------+----+------+\n",
            "|Naveen|Engineering| 70000|2023|   4.7|\n",
            "| Rahul|Engineering| 65000|2023|   4.9|\n",
            "+------+-----------+------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Window & Rank**"
      ],
      "metadata": {
        "id": "n2CluFeVQgXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Rank employees by salary department-wise\n",
        "windowDept = Window.partitionBy(\"Department\").orderBy(col(\"Salary\").desc())\n",
        "df_emp.withColumn(\"SalaryRank\", rank().over(windowDept)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmrbfknQQoxQ",
        "outputId": "a01c1307-0656-4885-d488-e96c50612c22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----------+\n",
            "|  Name| Department|Salary|SalaryRank|\n",
            "+------+-----------+------+----------+\n",
            "|Naveen|Engineering| 70000|         1|\n",
            "| Rahul|Engineering| 65000|         2|\n",
            "| Priya|Engineering| 60000|         3|\n",
            "| Karan|         HR| 53000|         1|\n",
            "|Ananya|         HR| 52000|         2|\n",
            "|  Zoya|  Marketing| 48000|         1|\n",
            "|Fatima|  Marketing| 45000|         2|\n",
            "+------+-----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Cumulative salary in each department\n",
        "windowCumSum = Window.partitionBy(\"Department\").orderBy(\"Salary\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "df_emp.withColumn(\"CumulativeSalary\", _sum(\"Salary\").over(windowCumSum)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai_cYClRQ3qI",
        "outputId": "ff446820-99ef-4395-f3ce-4d4448196cde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----------------+\n",
            "|  Name| Department|Salary|CumulativeSalary|\n",
            "+------+-----------+------+----------------+\n",
            "| Priya|Engineering| 60000|           60000|\n",
            "| Rahul|Engineering| 65000|          125000|\n",
            "|Naveen|Engineering| 70000|          195000|\n",
            "|Ananya|         HR| 52000|           52000|\n",
            "| Karan|         HR| 53000|          105000|\n",
            "|Fatima|  Marketing| 45000|           45000|\n",
            "|  Zoya|  Marketing| 48000|           93000|\n",
            "+------+-----------+------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date Operations**"
      ],
      "metadata": {
        "id": "PKudb1rwRCGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Add JoinDate (random dates between 2020 and 2023)\n",
        "\n",
        "# Generate random join dates\n",
        "join_dates = [random_date() for _ in range(len(data))]\n",
        "\n",
        "# Append join_dates to each row\n",
        "from pyspark.sql import Row\n",
        "rows_with_dates = [Row(Name=row[0], Department=row[1], Salary=row[2], JoinDate=join_dates[i]) for i, row in enumerate(data)]\n",
        "\n",
        "# Create new DataFrame with JoinDate\n",
        "df_with_dates = spark.createDataFrame(rows_with_dates)\n",
        "df_with_dates.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9KrQOSRREnK",
        "outputId": "f9965062-5675-4d2e-a377-b90c7021a953"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----------+\n",
            "|  Name| Department|Salary|  JoinDate|\n",
            "+------+-----------+------+----------+\n",
            "|Ananya|         HR| 52000|2021-02-10|\n",
            "| Rahul|Engineering| 65000|2023-03-26|\n",
            "| Priya|Engineering| 60000|2022-05-02|\n",
            "|  Zoya|  Marketing| 48000|2020-07-09|\n",
            "| Karan|         HR| 53000|2023-09-29|\n",
            "|Naveen|Engineering| 70000|2021-08-08|\n",
            "|Fatima|  Marketing| 45000|2021-09-12|\n",
            "+------+-----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date, current_date, datediff\n",
        "\n",
        "df_with_dates = df_with_dates.withColumn(\"JoinDate\", to_date(\"JoinDate\", \"yyyy-MM-dd\"))\n",
        "df_with_dates = df_with_dates.withColumn(\"YearsWithCompany\", (datediff(current_date(), col(\"JoinDate\")) / 365).cast(\"int\"))\n",
        "df_with_dates.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7-yeOfuVYf2",
        "outputId": "458fd2f6-0771-4d07-c44b-38acba3babfc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----------+----------------+\n",
            "|  Name| Department|Salary|  JoinDate|YearsWithCompany|\n",
            "+------+-----------+------+----------+----------------+\n",
            "|Ananya|         HR| 52000|2021-02-10|               4|\n",
            "| Rahul|Engineering| 65000|2023-03-26|               2|\n",
            "| Priya|Engineering| 60000|2022-05-02|               3|\n",
            "|  Zoya|  Marketing| 48000|2020-07-09|               4|\n",
            "| Karan|         HR| 53000|2023-09-29|               1|\n",
            "|Naveen|Engineering| 70000|2021-08-08|               3|\n",
            "|Fatima|  Marketing| 45000|2021-09-12|               3|\n",
            "+------+-----------+------+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. YearsWithCompany\n",
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "df_final = df_with_dates.withColumn(\"JoinDate\", to_date(\"JoinDate\", \"yyyy-MM-dd\"))\n",
        "df_final = df_final.withColumn(\"YearsWithCompany\", (datediff(current_date(), col(\"JoinDate\")) / 365).cast(\"int\"))"
      ],
      "metadata": {
        "id": "yx8b1D5CVriX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Writing to Files**"
      ],
      "metadata": {
        "id": "U7YXUZyWV4dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Write full employee DataFrame to CSV with headers\n",
        "df_final.write.option(\"header\", True).mode(\"overwrite\").csv(\"/content/employee_data_output.csv\")"
      ],
      "metadata": {
        "id": "kWCXpuwXV7Ya"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Save the joined DataFrame to a Parquet file\n",
        "df_joined.write.mode(\"overwrite\").parquet(\"/content/employee_performance.parquet\")\n"
      ],
      "metadata": {
        "id": "s_RNoDmhWQGH"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}